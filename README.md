# Slooze Data Engineering Pipeline

<p align="center">
  <img src="public/FFFFFF-1.png" alt="Slooze Logo" width="300">
</p>

<p align="center">
  <strong>ğŸš€ Production-Grade B2B Marketplace Intelligence Pipeline</strong>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#quick-start">Quick Start</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#usage">Usage</a> â€¢
  <a href="#analysis">Analysis</a>
</p>

---

## ğŸ“Œ Challenge Overview

This repository contains a **comprehensive solution** for the Slooze Data Engineering Take-Home Challenge, demonstrating:

- **Part A**: Advanced web scraping/data collection from B2B marketplaces
- **Part B**: In-depth Exploratory Data Analysis with interactive visualizations

---

## âœ¨ Features

### ğŸ•·ï¸ Advanced Data Collection
- **Async HTTP Client** - Concurrent requests using `aiohttp` for high performance
- **Intelligent Rate Limiting** - Token bucket algorithm respects target sites
- **User Agent Rotation** - Avoids detection with realistic browser fingerprints
- **Retry Logic** - Exponential backoff with `tenacity` for resilience
- **Data Validation** - Pydantic models ensure data quality at ingestion
- **Multi-Source Support** - Extensible parser architecture for different marketplaces

### ğŸ“Š Comprehensive EDA
- **Statistical Analysis** - Distributions, correlations, outlier detection
- **Interactive Visualizations** - Plotly dashboards for exploration
- **NLP Text Analysis** - TF-IDF keywords, word clouds
- **ML Clustering** - K-Means price segmentation
- **Auto-Generated Insights** - Business intelligence extraction
- **Beautiful HTML Reports** - Premium, shareable reports

### ğŸ—ï¸ Production-Grade Architecture
- **SQLite Database** - Persistent storage with SQLAlchemy ORM
- **Configuration Management** - Centralized, environment-aware config
- **Rich CLI** - Beautiful command-line interface with Typer
- **Comprehensive Logging** - Structured logs for debugging
- **Type Safety** - Full type hints throughout

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Windows/Linux/macOS

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd Slooze

# Create virtual environment
python -m venv env

# Activate (Windows)
.\env\Scripts\activate

# Activate (Linux/macOS)
source env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Run the Pipeline

```bash
# Run complete pipeline with mock data (recommended for demo)
python src/cli.py pipeline --mock

# Or run individual steps:
# 1. Collect data
python src/cli.py collect --mock

# 2. Run analysis
python src/cli.py analyze

# Check status
python src/cli.py status
```

---

## ğŸ—ï¸ Architecture

```
D:\Slooze\
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ cli.py              # Typer CLI application
â”‚   â”œâ”€â”€ config.py           # Centralized configuration
â”‚   â”œâ”€â”€ models.py           # Pydantic data models
â”‚   â”œâ”€â”€ database.py         # SQLAlchemy ORM layer
â”‚   â”œâ”€â”€ collector.py        # Advanced async scraper
â”‚   â””â”€â”€ eda_analysis.py     # Comprehensive EDA engine
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ slooze_data.db      # SQLite database
â”‚   â””â”€â”€ collected_data.csv  # Exported CSV
â”‚
â”œâ”€â”€ ğŸ“ outputs/
â”‚   â”œâ”€â”€ ğŸ“ charts/          # Visualizations (PNG + HTML)
â”‚   â””â”€â”€ ğŸ“ reports/         # Generated HTML reports
â”‚
â”œâ”€â”€ ğŸ“ logs/                # Application logs
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md
```

### Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLI Interface                             â”‚
â”‚                    (cli.py - Typer)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                           â”‚
                  â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Data Collector    â”‚     â”‚     EDA Engine          â”‚
    â”‚   (collector.py)    â”‚     â”‚   (eda_analysis.py)     â”‚
    â”‚                     â”‚     â”‚                         â”‚
    â”‚ â€¢ Async HTTP        â”‚     â”‚ â€¢ Statistical Analysis  â”‚
    â”‚ â€¢ Rate Limiting     â”‚     â”‚ â€¢ Plotly Visualizations â”‚
    â”‚ â€¢ UA Rotation       â”‚     â”‚ â€¢ NLP Analysis          â”‚
    â”‚ â€¢ Pydantic Valid.   â”‚     â”‚ â€¢ ML Clustering         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â€¢ Report Generation     â”‚
               â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                             â”‚
               â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              Database Layer (database.py)            â”‚
    â”‚                   SQLAlchemy ORM                     â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
    â”‚              â”‚   SQLite Database    â”‚                â”‚
    â”‚              â”‚   (slooze_data.db)   â”‚                â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Usage

### CLI Commands

| Command | Description |
|---------|-------------|
| `python src/cli.py collect` | Scrape data from marketplaces |
| `python src/cli.py collect --mock` | Generate realistic mock data |
| `python src/cli.py analyze` | Run EDA and generate reports |
| `python src/cli.py pipeline` | Run complete ETL + EDA |
| `python src/cli.py status` | Show current data statistics |
| `python src/cli.py clean` | Clear all data and outputs |

### Configuration

Edit `src/config.py` to customize:

```python
@dataclass
class ScraperConfig:
    CATEGORIES: List[str] = [
        "industrial-pumps",
        "electric-motors",
        "cnc-machines",
        # Add more categories...
    ]
    
    RATE_LIMIT: int = 30  # Requests per minute
    MAX_CONCURRENT_REQUESTS: int = 5
```

---

## ğŸ“Š Analysis Outputs

### Generated Reports

After running the analysis, you'll find:

| File | Description |
|------|-------------|
| `outputs/reports/analysis_report.html` | ğŸ“„ Premium HTML dashboard |
| `outputs/charts/executive_summary.png` | ğŸ“Š 4-panel summary chart |
| `outputs/charts/price_distribution_interactive.html` | ğŸ’° Price analysis |
| `outputs/charts/regional_analysis_interactive.html` | ğŸ—ºï¸ Regional insights |
| `outputs/charts/supplier_analysis_interactive.html` | ğŸ­ Supplier breakdown |
| `outputs/charts/category_sunburst.html` | ğŸŒ Hierarchy view |
| `outputs/charts/price_clusters.html` | ğŸ¯ Segmentation |
| `outputs/charts/wordcloud.png` | ğŸ”¤ Product keywords |

### Sample Insights

The pipeline automatically generates insights like:

- ğŸ“Š Price distribution patterns and skewness
- ğŸ™ï¸ Leading manufacturing hubs by product count
- âœ“ Supplier verification rates
- ğŸ¯ Price segment distribution
- ğŸ”¤ Top product keywords by TF-IDF

---

## ğŸ”§ Technical Highlights

### Data Validation with Pydantic

```python
class ProductListing(BaseModel):
    product_name: str = Field(..., min_length=3, max_length=500)
    price_min: Optional[float] = Field(None, ge=0)
    quality_score: float = Field(default=1.0, ge=0, le=1)
    
    @model_validator(mode='after')
    def calculate_quality_score(self):
        # Auto-calculate data quality...
```

### Async Scraping with Rate Limiting

```python
class RateLimiter:
    """Token bucket algorithm for respectful scraping."""
    
    async def acquire(self):
        async with self._lock:
            # Refill tokens based on elapsed time
            # Wait if insufficient tokens
```

### Interactive Plotly Dashboards

```python
fig = make_subplots(
    rows=1, cols=2,
    subplot_titles=('Price Distribution', 'Price by Category')
)
fig.add_trace(go.Histogram(...))
fig.write_html("price_distribution.html")
```

---

## ğŸ“ˆ Performance

| Metric | Value |
|--------|-------|
| Mock data generation | ~300 products in <2s |
| Database insertion | ~1000 records/second (batch) |
| Full EDA pipeline | <30 seconds |
| Report generation | <5 seconds |

---

## ğŸ§ª Testing

```bash
# Run with mock data for testing
python src/cli.py pipeline --mock

# Check database status
python src/cli.py status
```

---

## ğŸ“ License

This solution was created as part of the Slooze hiring challenge.

**Â© Slooze. All Rights Reserved.**

---

## ğŸ‘¤ Author

**[Your Name]**  
Data Engineering Candidate

---

<p align="center">
  Built with â¤ï¸ using Python, Plotly, SQLAlchemy, and Rich
</p>
